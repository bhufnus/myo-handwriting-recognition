Old Model sees:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Average: 0.5    â”‚ â†’ Predict: "A" (maybe)
â”‚ Max: 0.8        â”‚
â”‚ Min: 0.2        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

LSTM sees:
â”Œâ”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”
â”‚1â”‚2â”‚3â”‚4â”‚5â”‚6â”‚7â”‚8â”‚9â”‚10â”‚ â†’ Time steps
â”œâ”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¤
â”‚â†‘â”‚â†‘â”‚â†‘â”‚â†’â”‚â†’â”‚â†“â”‚â†“â”‚â†“â”‚â†‘â”‚â†‘â”‚ â†’ Movement pattern

06/27/2025 - I wasn't able to get accurate predictions even after creating and retraining a sequence model. My guess is the EMG signal is being factored in too much. Let's run a script and see what our weights are.

1ï¸âƒ£ Equal Weighting (Original):
   EMG range: -39.713 to 36.268
   Quaternion range: -0.304 to 0.313
   EMG std: 9.911
   Quaternion std: 0.102

2ï¸âƒ£ Position-Focused Weighting (80% position, 20% EMG):
   EMG range: -7.943 to 7.254
   Quaternion range: -0.243 to 0.250
   EMG std: 1.982
   Quaternion std: 0.081

3ï¸âƒ£ Custom Weighting (30% EMG, 70% position):
   EMG range: -11.914 to 10.880
   Quaternion range: -0.213 to 0.219
   EMG std: 2.973
   Quaternion std: 0.071

4ï¸âƒ£ Position-Only (100% position):
   EMG range: 0.000 to 0.000
   Quaternion range: -0.304 to 0.313
   EMG std: 0.000
   Quaternion std: 0.102

ğŸ“Š Summary:
   â€¢ Equal weighting: EMG dominates due to higher variance
   â€¢ Position-focused: Balances the influence, giving more weight to position
   â€¢ Position-only: Completely ignores EMG data

ğŸ” Understanding the Results
1ï¸âƒ£ Equal Weighting (Original)
EMG range: -39.713 to 36.268 (very wide range)
Quaternion range: -0.304 to 0.313 (much smaller range)
EMG std: 9.911 (high variance)
Quaternion std: 0.102 (low variance)
Problem: EMG data has 97x higher variance than quaternion data! This means the model was essentially ignoring position data because EMG was dominating the learning process.

Turns out I was right. The EMG data has 97x higher variance than quaternion data! This means the model was essentially ignoring position data because EMG was dominating the learning process.




06/30/2025

Lets visualize our data. Built a confusion matrix to compare different learning models. Also displays each models top features. The lack of a strong diagonal on the confusion matrix lead me to the solution of stratified splitting to give me a fair representative evaluation of the models on all classes.